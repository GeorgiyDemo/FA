{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лекция 1 (часть 2): Введение в работу с PyTorch\n",
    "\n",
    "__Автор: Сергей Вячеславович Макрушин__ e-mail: SVMakrushin@fa.ru \n",
    "\n",
    "Финансовый универсиет, 2021 г. \n",
    "\n",
    "При подготовке лекции использованы материалы:\n",
    "* ...\n",
    "\n",
    "V 0.5 04.02.2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разделы: <a class=\"anchor\" id=\"разделы\"></a>\n",
    "* [Установка PyTorch](#установка)\n",
    "* [Тензоры и опреации с ними в PyTorch](#тензоры)\n",
    "    * [Создание тензоров](#создание-тензоров)\n",
    "    * [Операции с тензорами](#операции-тензоры)    \n",
    "        * [Арифметические операции и математические функции:](#aрифметические)        \n",
    "        * [Операции, изменяющие размер тензора](#размер)        \n",
    "        * [Операции агрегации](#агрегации)        \n",
    "        * [Матричные операции](#aрифметические)                \n",
    "-\n",
    "\n",
    "* [к оглавлению](#разделы)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "﻿<style>\r\n",
       "\r\n",
       "\r\n",
       "b.n {\r\n",
       "    font-weight: normal;        \r\n",
       "}\r\n",
       "\r\n",
       "b.grbg {\r\n",
       "    background-color: #a0a0a0;      \r\n",
       "}\r\n",
       "\r\n",
       "b.r {\r\n",
       "    color: #ff0000;    \r\n",
       "}\r\n",
       "\r\n",
       "\r\n",
       "b.b {    \r\n",
       "    color: #0000ff;    \r\n",
       "}\r\n",
       "\r\n",
       "b.g {\r\n",
       "    color: #00ff00;    \r\n",
       "}\r\n",
       "\r\n",
       "\r\n",
       "// add your CSS styling here\r\n",
       "\r\n",
       "list-style: none;\r\n",
       "\r\n",
       "ul.s {\r\n",
       "//    list-style-type: none;\r\n",
       "    list-style: none;\r\n",
       "//    background-color: #ff0000;  \r\n",
       "//    color: #ffff00;\r\n",
       "//  padding-left: 1.2em;\r\n",
       "//  text-indent: -1.2em;\r\n",
       "}\r\n",
       "\r\n",
       "li.t {\r\n",
       "    list-style: none;\r\n",
       "//  padding-left: 1.2em;\r\n",
       "//  text-indent: -1.2em;    \r\n",
       "}\r\n",
       "\r\n",
       "\r\n",
       "*.r {\r\n",
       "    color: #ff0000;    \r\n",
       "}\r\n",
       "\r\n",
       "li.t:before {\r\n",
       "    content: \"\\21D2\";    \r\n",
       "//    content: \"►\";\r\n",
       "//    padding-left: -1.2em;    \r\n",
       "    text-indent: -1.2em;    \r\n",
       "    display: block;\r\n",
       "    float: left;\r\n",
       "    \r\n",
       "    \r\n",
       "//    width: 1.2em;\r\n",
       "//    color: #ff0000;\r\n",
       "}\r\n",
       "\r\n",
       "i.m:before {\r\n",
       "    font-style: normal;    \r\n",
       "    content: \"\\21D2\";  \r\n",
       "}\r\n",
       "i.m {\r\n",
       "    font-style: normal; \r\n",
       "}    \r\n",
       "\r\n",
       "/*--------------------*/\r\n",
       "/* em {\r\n",
       "    font-style: normal; \r\n",
       "} */\r\n",
       "\r\n",
       "\r\n",
       "em.bl {\r\n",
       "    font-style: normal;     \r\n",
       "    font-weight: bold;        \r\n",
       "}\r\n",
       "\r\n",
       "/* em.grbg {\r\n",
       "    font-style: normal;         \r\n",
       "    background-color: #a0a0a0;      \r\n",
       "} */\r\n",
       "\r\n",
       "em.cr {\r\n",
       "    font-style: normal;         \r\n",
       "    color: #ff0000;    \r\n",
       "}\r\n",
       "\r\n",
       "em.cb {    \r\n",
       "    font-style: normal;         \r\n",
       "    color: #0000ff;    \r\n",
       "}\r\n",
       "\r\n",
       "em.cg {\r\n",
       "    font-style: normal;         \r\n",
       "    color: #00ff00;    \r\n",
       "}\r\n",
       "\r\n",
       "/*--------------------*/\r\n",
       "\r\n",
       "em.qs {\r\n",
       "    font-style: normal; \r\n",
       "}\r\n",
       "\r\n",
       "em.qs::before {\r\n",
       "    font-weight: bold;    \r\n",
       "    color: #ff0000;    \r\n",
       "    content: \"Q:\";  \r\n",
       "}\r\n",
       "\r\n",
       "em.an {\r\n",
       "    font-style: normal; \r\n",
       "}\r\n",
       "\r\n",
       "em.an:before {\r\n",
       "    font-weight: bold;    \r\n",
       "    color: #0000ff;    \r\n",
       "    content: \"A:\";  \r\n",
       "}\r\n",
       "    \r\n",
       "em.nt {\r\n",
       "    font-style: normal; \r\n",
       "}\r\n",
       "\r\n",
       "em.nt:before {\r\n",
       "    font-weight: bold;    \r\n",
       "    color: #0000ff;    \r\n",
       "    content: \"Note:\";  \r\n",
       "}    \r\n",
       "    \r\n",
       "em.ex {\r\n",
       "    font-style: normal; \r\n",
       "}\r\n",
       "\r\n",
       "em.ex:before {\r\n",
       "    font-weight: bold;    \r\n",
       "    color: #00ff00;    \r\n",
       "    content: \"Ex:\";  \r\n",
       "} \r\n",
       "    \r\n",
       "em.df {\r\n",
       "    font-style: normal; \r\n",
       "}\r\n",
       "\r\n",
       "em.df:before {\r\n",
       "    font-weight: bold;    \r\n",
       "    color: #0000ff;    \r\n",
       "    content: \"Def:\";  \r\n",
       "}    \r\n",
       "\r\n",
       "em.pl {\r\n",
       "    font-style: normal; \r\n",
       "}\r\n",
       "\r\n",
       "em.pl:before {\r\n",
       "    font-weight: bold;    \r\n",
       "    color: #0000ff;    \r\n",
       "    content: \"+\";  \r\n",
       "}    \r\n",
       "\r\n",
       "em.mn {\r\n",
       "    font-style: normal; \r\n",
       "}\r\n",
       "\r\n",
       "em.mn:before {\r\n",
       "    font-weight: bold;    \r\n",
       "    color: #0000ff;    \r\n",
       "    content: \"-\";  \r\n",
       "}        \r\n",
       "\r\n",
       "em.plmn {\r\n",
       "    font-style: normal; \r\n",
       "}\r\n",
       "\r\n",
       "em.plmn:before {\r\n",
       "    font-weight: bold;    \r\n",
       "    color: #0000ff;    \r\n",
       "    content: \"\\00B1\";\\\\\"&plusmn;\";  \r\n",
       "}\r\n",
       "    \r\n",
       "em.hn {\r\n",
       "    font-style: normal; \r\n",
       "}\r\n",
       "\r\n",
       "em.hn:before {\r\n",
       "    font-weight: bold;    \r\n",
       "    color: #0000ff;    \r\n",
       "    content: \"\\21D2\";\\\\\"&rArr;\";  \r\n",
       "}     \r\n",
       "    \r\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# загружаем стиль для оформления презентации\n",
    "from IPython.display import HTML\n",
    "from urllib.request import urlopen\n",
    "html = urlopen(\"file:./lec_v1.css\")\n",
    "HTML(html.read().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### Современные инструменты для создание моделей на основе ИНС\n",
    "\n",
    "* TensorFlow / Keras \n",
    "* PyTorch\n",
    "\n",
    "\n",
    "TODO: более полный обзор современного \"рынка\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Установка PyTorch <a class=\"anchor\" id=\"установка\"></a>\n",
    "* [к оглавлению](#разделы)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Стартуем консоль Анаконды:\n",
    "\n",
    "<center> \n",
    "<img src=\"./img/lnnp2_anaconda_prompt1.png\" alt=\"Запуск консоли Анаконды\" style=\"width: 200px;\"/><br/>\n",
    "    <b>Запуск консоли Анаконды</b>    \n",
    "</center> \n",
    "\n",
    "Далее в консоли:\n",
    "2. Определяем текущую версию Python. Пример:\n",
    "\n",
    "```console\n",
    "(base) C:\\Users\\alpha>python --version\n",
    "Python 3.7.6\n",
    "```\n",
    "\n",
    "3. Экспортируем текущую версию окружения (например, в файл `environment.yml` ). Пример:\n",
    "\n",
    "```console\n",
    "(base) C:\\Users\\alpha>conda env export > environment.yml\n",
    "```\n",
    "4. Создаем новое __виртуальное окружение__ для текущей версии Python (можете выбрать удобноее Вам имя виртуального окружения).\n",
    "    * <em class=\"qs\"></em> Что такое __virtualenv__ (виртуальное окружение Python) и зачем оно нужно?\n",
    "    * <em class=\"an\"></em> Базовые ответы есть тут: \n",
    "        * https://pythontips.com/2013/07/30/what-is-virtualenv/\n",
    "        * https://stackoverflow.com/questions/41972261/what-is-a-virtualenv-and-why-should-i-use-one\n",
    "        * Важно знать, что у Anaconda есть собственный инсрументарий для работы c __virtualenv__, и если вы пользуетесь анакондой, то предпочитительно пользоваться им:\n",
    "            * Шпаргалка с кратким набором команд (см. раздел \"Using environments\"): https://docs.conda.io/projects/conda/en/4.6.0/_downloads/52a95608c49671267e40c689e0bc00ca/conda-cheatsheet.pdf\n",
    "            * Документация: https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html\n",
    "    * Пример (`pyTorch_1_5v2` - имя нового окружения, `-f=environment.yml` - импортируем окружение из файла, созданного на шаге 3):\n",
    "\n",
    "```console\n",
    "(base) C:\\Users\\alpha>conda-env create -n pyTorch_1_5v2 python=3.7 -f=environment.yml\n",
    "Collecting package metadata (repodata.json): done\n",
    "Solving environment: done\n",
    "\n",
    "\n",
    "==> WARNING: A newer version of conda exists. <==\n",
    "  current version: 4.8.2\n",
    "  latest version: 4.8.3\n",
    "\n",
    "Please update conda by running\n",
    "\n",
    "    $ conda update -n base -c defaults conda\n",
    "\n",
    "\n",
    "\n",
    "Downloading and Extracting Packages\n",
    "anaconda-navigator-1 | 4.4 MB    | ############################################################################ | 100%\n",
    "Preparing transaction: done\n",
    "Verifying transaction: done\n",
    "Executing transaction: done\n",
    "#\n",
    "# To activate this environment, use\n",
    "#\n",
    "#     $ conda activate pyTorch_1_5v2\n",
    "#\n",
    "# To deactivate an active environment, use\n",
    "#\n",
    "#     $ conda deactivate\n",
    "```\n",
    "            \n",
    "4. С помощью `conda env list` Просматриваем список доступных виртуальных окружений. Пример:\n",
    "\n",
    "```console\n",
    "(base) C:\\Users\\alpha>conda env list\n",
    "# conda environments:\n",
    "#\n",
    "base                  *  C:\\ProgramData\\Anaconda3\n",
    "pyTorch_1_5              C:\\Users\\alpha\\.conda\\envs\\pyTorch_1_5\n",
    "pyTorch_1_5v2            C:\\Users\\alpha\\.conda\\envs\\pyTorch_1_5v2\n",
    "```\n",
    "\n",
    "4. С помощью команды `activate` переходим в созданное окружение. В результате имя окружения перед приглашением должно измениться на имя выбранного окружения. Пример:\n",
    "\n",
    "```console\n",
    "(base) C:\\Users\\alpha>activate pyTorch_1_5v2\n",
    "\n",
    "(pyTorch_1_5v2) C:\\Users\\alpha>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- <center> \n",
    "<img src=\"./img/lnnp2_anaconda_prompt2.png\" alt=\"Создание новго virtualenv\" style=\"width: 600px;\"/><br/>\n",
    "    <b>Создание новго virtualenv</b>    \n",
    "</center>  -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. На сайте https://pytorch.org выбираем конфигурацию в которой необходимо установить PyTorch и копируем строку из поля __Run this Command__  и выполняем ее в консоли в новом окружении, например:\n",
    "\n",
    "```console\n",
    "(pyTorch_1_5) C:\\Users\\alpha>conda install pytorch torchvision cpuonly -c pytorch\n",
    "```\n",
    "\n",
    "Соглашаемся на установку новых пакетов:\n",
    "\n",
    "```console\n",
    "The following NEW packages will be INSTALLED:\n",
    "\n",
    "  blas               pkgs/main/win-64::blas-1.0-mkl\n",
    "  cpuonly            pytorch/noarch::cpuonly-1.0-0\n",
    "  freetype           pkgs/main/win-64::freetype-2.9.1-ha9979f8_1\n",
    "  icc_rt             pkgs/main/win-64::icc_rt-2019.0.0-h0cc432a_1\n",
    "  intel-openmp       pkgs/main/win-64::intel-openmp-2020.0-166\n",
    "  jpeg               pkgs/main/win-64::jpeg-9b-hb83a4c4_2\n",
    "  libpng             pkgs/main/win-64::libpng-1.6.37-h2a8f88b_0\n",
    "  libtiff            pkgs/main/win-64::libtiff-4.1.0-h56a325e_0\n",
    "  mkl                pkgs/main/win-64::mkl-2020.0-166\n",
    "  mkl-service        pkgs/main/win-64::mkl-service-2.3.0-py37hb782905_0\n",
    "  mkl_fft            pkgs/main/win-64::mkl_fft-1.0.15-py37h14836fe_0\n",
    "  mkl_random         pkgs/main/win-64::mkl_random-1.1.0-py37h675688f_0\n",
    "  ninja              pkgs/main/win-64::ninja-1.9.0-py37h74a9793_0\n",
    "  numpy              pkgs/main/win-64::numpy-1.18.1-py37h93ca92e_0\n",
    "  numpy-base         pkgs/main/win-64::numpy-base-1.18.1-py37hc3f5095_1\n",
    "  olefile            pkgs/main/win-64::olefile-0.46-py37_0\n",
    "  pillow             pkgs/main/win-64::pillow-7.0.0-py37hcc1f983_0\n",
    "  pytorch            pytorch/win-64::pytorch-1.5.0-py3.7_cpu_0\n",
    "  six                pkgs/main/win-64::six-1.14.0-py37_0\n",
    "  tk                 pkgs/main/win-64::tk-8.6.8-hfa6e2cd_0\n",
    "  torchvision        pytorch/win-64::torchvision-0.6.0-py37_cpu\n",
    "  xz                 pkgs/main/win-64::xz-5.2.5-h62dcd97_0\n",
    "  zstd               pkgs/main/win-64::zstd-1.3.7-h508b16e_0\n",
    "\n",
    "\n",
    "Proceed ([y]/n)? y\n",
    "```\n",
    "\n",
    "6. Проверяем успешность установки PyTorch:\n",
    "  \n",
    "    * В консоли, в текущем виртуальном окружении стартуем консоль Python:\n",
    "\n",
    "```console\n",
    "(pyTorch_1_5) C:\\Users\\alpha>python\n",
    "Python 3.7.7 (default, Apr 15 2020, 05:09:04) [MSC v.1916 64 bit (AMD64)] :: Anaconda, Inc. on win32\n",
    "Type \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n",
    ">>>```\n",
    "   \n",
    "   * В консоли импортируем модуль torch, и пишем тривиальное выражение с использованием torch:\n",
    "```console\n",
    ">>> import torch\n",
    ">>> x = torch.rand(3)\n",
    "```\n",
    "\n",
    "* для выхода из консоли Python пишем:\n",
    "```console\n",
    ">>> exit()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--\n",
    "1. В новом виртуальном окружении выполняем комадну \n",
    "\n",
    "```console\n",
    "(pyTorch_1_5) C:\\Users\\alpha>pip install ipykernel\n",
    "```\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Добавление нового виртуального окружения к Jupyter Notebook__\n",
    "\n",
    "1. В новом виртуальном окружении выполняем комадну настройки ipykernel (в параемтре __name__ передаем имя нового виртуального окружения):\n",
    "```console\n",
    "(pyTorch_1_5v2) C:\\Users\\alpha>python -m ipykernel install --user --name=pyTorch_1_5v2\n",
    "```\n",
    "* настройка `ipykernel` позволяет jupyter работать с разными языками (например: julia, R; кстати JuPyteR, называется так именно из-за поддержки работы с этими (и многими другими) языками) и разными версями Python (и, естественно, разными virtualenv). Базовое описание архитектуры jupyter дано, например, тут: https://jupyter.readthedocs.io/en/latest/architecture/how_jupyter_ipython_work.html\n",
    "\n",
    "* Примеры работы с `ipykernel` есть тут:\n",
    "    * (ищите поиском по странице `ipykernel`)  https://www.datacamp.com/community/tutorials/tutorial-jupyter-notebook\n",
    "    * и тут: http://queirozf.com/entries/jupyter-kernels-how-to-add-change-remove\n",
    "\n",
    "2. Стартуем Jupyter Notebook для нового виртуалного окружения:\n",
    "\n",
    "<center> \n",
    "<img src=\"./img/lnnp2_anaconda_2.png\" alt=\"Старт Jupyter Notebook для нового виртуалного окружения\" style=\"width: 300px;\"/><br/>\n",
    "    <b>Старт Jupyter Notebook для нового виртуалного окружения</b>    \n",
    "</center>\n",
    "\n",
    "\n",
    "3. Стратуем Jupyter Notebook и убеждаемся что при создании нового ноутбука есть возможность выбрать новое окружение:\n",
    "\n",
    "<center> \n",
    "<img src=\"./img/lnnp2_jn2.png\" alt=\"Создание ноутбука в новом virtualenv\" style=\"width: 650px;\"/><br/>\n",
    "    <b>Создание ноутбука в новом virtualenv</b>    \n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Проверяем в каком окружении мы запустили ноутбук (звездочка должна стоять напротив нужного ноутбука):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# conda environments:\n",
      "#\n",
      "pyTorch_1_5              C:\\Users\\alpha\\.conda\\envs\\pyTorch_1_5\n",
      "base                  *  C:\\Users\\alpha\\.conda\\envs\\pyTorch_1_5v2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda env list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Проверяем что в новом ноутбуке можно успешно работать с PyTorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.5.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тензоры и опреации с ними в PyTorch <a class=\"anchor\" id=\"тензоры\"></a>\n",
    "* [к оглавлению](#разделы)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Что понимается под тензором в TensorFlow, PyTorch и аналогичных инструментах?__\n",
    "\n",
    "* <em class=\"df\"></em> __Тензор (в линейной алгербре)__ — объект линейной алгебры, линейно преобразующий элементы одного линейного пространства в элементы другого. Частными случаями тензоров являются скаляры, векторы, билинейные формы и т. п.\n",
    "\n",
    "* Часто тензор представляют как многомерную таблицу $ d \\times d \\times \\cdots \\times d $, заполненную числами - компонентами тензора (где $d$ — размерность векторного пространства, над которым задан тензор, а число размерностей совпадает рангом (валентностью) тензора. В случае ранга 2 запись тензора на письме выглядит как матрица.\n",
    "\n",
    "* Запись тензора в виде многомерной таблицы возможна __только после выбора базиса (системы координат)__ (кроме скаляров - тензоров размерности 0). Сам тензор как \"геометрическая сущность\" от выбора базиса не зависит. Это можно наглядно видеть на примере вектора (тензора ранга 1) при смене системы координат: \n",
    "    * при смене системы координат __компоненты вектора__ (и в общем случае - тензора) __меняются__ определённым образом.\n",
    "    * но сам __вектор__ — как \"геометрическая сущность\", образом которого может быть просто направленный отрезок — __при смене системы координат не изменяется__. Это же относится и к общему случаю - тензору.\n",
    "\n",
    "* В TensorFlow, PyTorch и  аналогичных библиотеках ключевыми объектами являются __тензоры__, но:\n",
    "    * __это не настоящие тензоры линейной алгебры__, а просто __многомерные таблицы__. В частности:\n",
    "        * эти тензоры __не прдедусматривают определение базиса и возможности его изменения__.\n",
    "    * для тензов (многомерных таблиц) в TensorFlow определены различные операции, важные для построения графа потока вычислений для численногомоделирования ИНС и ряда других приложений.\n",
    "    \n",
    "* Далее под тензорами мы будем иметь в виду то, что под ними понимается в TensorFlow, PyTorch и других аналогичных библиотеках.\n",
    "* __Тензоры__ в TensorFlow, PyTorch и аналогичных библиотеках в очень многих аспектах __похожы на массивы NumPy__.\n",
    "    \n",
    "<center> \n",
    "<img src=\"./img/ker_5.png\" alt=\"\"Тензоры\" в TensorFlow и аналогичных инструментах.\" style=\"width: 600px;\"/><br/>\n",
    "    <b>\"Тензоры\" в TensorFlow и аналогичных инструментах.</b>    \n",
    "</center> \n",
    "\n",
    "Тензоры в TensorFlow по логике использования и интерфейсу очень близки к `ndarray` в NumPy.\n",
    "* тензор размерности 0 - скаляр\n",
    "* тензор размерности 1 - вектор (одномерный массив)\n",
    "* тензор размерности 2 - матрица (двухмерный массив массив)\n",
    "* тензор размерности N - N-мерный массив"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Создание тензоров <a class=\"anchor\" id=\"создание-тензоров\"></a>\n",
    "* [к оглавлению](#разделы)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0469e-38])\n",
      "tensor([ 0.0000e+00,  0.0000e+00, -5.4389e-27])\n",
      "tensor([[4.3726e-05, 2.6881e-06, 4.2039e-45],\n",
      "        [0.0000e+00, 1.4013e-45, 0.0000e+00]])\n",
      "tensor([[[0., 0., 0.],\n",
      "         [0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.],\n",
      "         [0., 0., 0.]]])\n",
      "tensor([[[[8.9082e-39, 4.2246e-39, 1.0194e-38],\n",
      "          [9.1837e-39, 8.4490e-39, 1.0102e-38]],\n",
      "\n",
      "         [[1.0561e-38, 1.0286e-38, 7.7144e-39],\n",
      "          [1.0469e-38, 9.5510e-39, 4.5001e-39]]],\n",
      "\n",
      "\n",
      "        [[[4.8674e-39, 9.9184e-39, 9.0000e-39],\n",
      "          [1.0561e-38, 1.0653e-38, 4.1327e-39]],\n",
      "\n",
      "         [[8.9082e-39, 9.8265e-39, 9.4592e-39],\n",
      "          [1.0561e-38, 1.0653e-38, 1.0469e-38]]]])\n"
     ]
    }
   ],
   "source": [
    "# В pytorch все основано на операциях с тензорами\n",
    "# Тензоры могут иметь:\n",
    "# 0 измерений - скаляры\n",
    "# 1 измерение - векторы\n",
    "# 2 измерения - матрицы\n",
    "# 3, 4, ... измерения - тензоры\n",
    "\n",
    "# Создание не инициализизированного тензора: torch.empty(size)\n",
    "# Нужно помнить, что перед использованием такого тензора его обязательно нужно инициализировать!\n",
    "\n",
    "x = torch.empty(1) # scalar\n",
    "print(x)\n",
    "x = torch.empty(3) # vector, 1D\n",
    "print(x)\n",
    "x = torch.empty(2,3) # matrix, 2D\n",
    "print(x)\n",
    "x = torch.empty(2,2,3) # tensor, 3 dimensions\n",
    "print(x)\n",
    "x = torch.empty(2,2,2,3) # tensor, 4 dimensions\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1.20556915e-311 3.16202013e-322 0.00000000e+000]\n",
      "  [1.20556915e-311 4.37257913e-005 2.68810072e-006]]\n",
      "\n",
      " [[4.20389539e-045 1.40129846e-045 8.37699992e+169]\n",
      "  [7.46072016e-038 8.24339157e-067 3.88813040e-033]]]\n"
     ]
    }
   ],
   "source": [
    "# Большинство операций с тензорами очень похожа на опреации с массивами NumPy, но часть имеют небольшие отличия: \n",
    "x_np = np.empty((2,2,3))\n",
    "print(x_np)\n",
    "# x_np = np.empty(2,2,3) # Ошибка!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7196, 0.0637, 0.9817],\n",
       "        [0.7202, 0.5812, 0.4477],\n",
       "        [0.9523, 0.2562, 0.3778],\n",
       "        [0.4160, 0.3518, 0.2820],\n",
       "        [0.6643, 0.2659, 0.4579]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Создание тензора, заполненного случайными значениями (равномерно распредленными в [0, 1]): torch.rand(size)\n",
    "x = torch.rand(5, 3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# Создание тензоров заполненных:\n",
    "# нулями: \n",
    "x = torch.zeros(5, 3)\n",
    "print(x)\n",
    "# единицами: \n",
    "x = torch.ones(5, 3)\n",
    "print(x)\n",
    "# тензор c единицами на главной диагонали:\n",
    "x = torch.eye(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# определение размера тензора:\n",
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "# для каждого тензора задан тип значений:\n",
    "print(x.dtype) # тип заданный автоматически\n",
    "\n",
    "# явное указание типа:\n",
    "x = torch.zeros(5, 3, dtype=torch.float16)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> \n",
    "<img src=\"./img/lnnp2_types1.png\" alt=\"Типы тензоров в PyTorch и массивов в NumPy\" style=\"width: 600px;\"/><br/>\n",
    "    <b>Типы тензоров в PyTorch и массивов в NumPy</b>    \n",
    "</center> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000e+00, 0.0000e+00, 2.1019e-44],\n",
       "        [0.0000e+00, 1.4013e-45, 0.0000e+00]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.Tensor(2, 3) # аналогично torch.empty\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6768, 0.5198, 0.6978],\n",
       "        [0.1581, 0.2027, 0.3723]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# создание тензора из данных:\n",
    "x = torch.Tensor([[0.6768, 0.5198, 0.6978], \n",
    "                  [0.1581, 0.2027, 0.3723]])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 6, 51,  6],\n",
      "        [15,  0, 37]]) <class 'torch.Tensor'> torch.int64\n",
      "tensor([[ 6., 51.,  6.],\n",
      "        [15.,  0., 37.]], dtype=torch.float64) <class 'torch.Tensor'> torch.float64\n"
     ]
    }
   ],
   "source": [
    "# создание тензора из данных:\n",
    "x = torch.tensor([[6, 51, 6],\n",
    "                  [15, 0, 37]])\n",
    "print(x, type(x), x.dtype)\n",
    "\n",
    "x = torch.tensor([[6, 51, 6],\n",
    "                  [15, 0, 37]], dtype=torch.float64)\n",
    "print(x, type(x), x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], dtype=torch.int32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# создание тензора из массива numpy:\n",
    "a = np.array([1, 2, 3])\n",
    "x = torch.from_numpy(a)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11  2  3]\n",
      "tensor([11,  2,  3], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# Carful: If the Tensor is on the CPU (not the GPU),\n",
    "# both objects will share the same memory location, so changing one\n",
    "# will also change the other\n",
    "\n",
    "a[0] += 10\n",
    "print(a)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11,  2,  3])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch to numpy with .numpy()\n",
    "# Специфика использования общего массива данных сохраняется!\n",
    "b = x.numpy()\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5000, 0.5000, 0.5000],\n",
       "        [0.5000, 0.5000, 0.5000]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# заполнение тензора значениями:\n",
    "x = torch.Tensor(2, 3)\n",
    "x.fill_(0.5) # функции, оканчивающиеся на _ меняют значение тензора слева от точки\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Справка по операциям создания тензоров тут: https://pytorch.org/docs/stable/torch.html#creation-ops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Операции с тензорами <a class=\"anchor\" id=\"операции-тензоры\"></a>\n",
    "* [к оглавлению](#разделы)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Арифметические операции и математические функции: <a class=\"anchor\" id=\"aрифметические\"></a>\n",
    "* [к оглавлению](#разделы)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:\n",
      " tensor([[0.2830, 0.7729],\n",
      "        [0.4965, 0.5944]])\n",
      "\n",
      "y:\n",
      " tensor([[0.3583, 0.9232],\n",
      "        [0.9019, 0.4403]])\n",
      "\n",
      "z = x + y:\n",
      " tensor([[0.6412, 1.6961],\n",
      "        [1.3984, 1.0347]])\n",
      "\n",
      "z = torch.add(x,y):\n",
      " tensor([[0.6412, 1.6961],\n",
      "        [1.3984, 1.0347]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(2, 2)\n",
    "print(f'x:\\n {x}\\n')\n",
    "y = torch.rand(2, 2)\n",
    "print(f'y:\\n {y}\\n')\n",
    "\n",
    "# поэлементное сложение:\n",
    "z = x + y\n",
    "print(f'z = x + y:\\n {z}\\n')\n",
    "z = torch.add(x,y)\n",
    "print(f'z = torch.add(x,y):\\n {z}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y2:\n",
      " tensor([[0.3583, 0.9232],\n",
      "        [0.9019, 0.4403]])\n",
      "\n",
      "y2.add_(x) in place:\n",
      " tensor([[0.6412, 1.6961],\n",
      "        [1.3984, 1.0347]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y2 = y.clone().detach() # копирование содержимого тензора в новый тензор\n",
    "print(f'y2:\\n {y2}\\n')\n",
    "\n",
    "# операции \"in place\" (помещают результат в объект слева от точки) в pytorch оканчиваются на _ :\n",
    "y2.add_(x)\n",
    "print(f'y2.add_(x) in place:\\n {y2}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z = torch.sub(x, y):\n",
      " tensor([[-0.0753, -0.1504],\n",
      "        [-0.4055,  0.1540]])\n",
      "\n",
      "z = torch.mul(x,y):\n",
      " tensor([[0.1014, 0.7135],\n",
      "        [0.4478, 0.2617]])\n",
      "\n",
      "z = torch.div(x,y):\n",
      " tensor([[0.7898, 0.8371],\n",
      "        [0.5505, 1.3498]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# вычитание:\n",
    "z = x - y\n",
    "z = torch.sub(x, y)\n",
    "print(f'z = torch.sub(x, y):\\n {z}\\n')\n",
    "\n",
    "# умножение (поэлементное!):\n",
    "z = x * y\n",
    "z = torch.mul(x,y)\n",
    "print(f'z = torch.mul(x,y):\\n {z}\\n')\n",
    "\n",
    "# деление:\n",
    "z = x / y\n",
    "z = torch.div(x,y)\n",
    "print(f'z = torch.div(x,y):\\n {z}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x - y:\n",
      " tensor([[-0.0753, -0.1504],\n",
      "        [-0.4055,  0.1540]])\n",
      "\n",
      "z = torch.abs(x - y):\n",
      " tensor([[0.0753, 0.1504],\n",
      "        [0.4055, 0.1540]])\n",
      "\n",
      "z.abs_():\n",
      " tensor([[0.0753, 0.1504],\n",
      "        [0.4055, 0.1540]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'x - y:\\n {x - y}\\n')\n",
    "\n",
    "z = torch.abs(x - y) # полэлементный рассчет модуля\n",
    "print(f'z = torch.abs(x - y):\\n {z}\\n')\n",
    "\n",
    "z = x - y\n",
    "z.abs_()\n",
    "print(f'z.abs_():\\n {z}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9602, 0.7159],\n",
       "        [0.8793, 0.8285]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cos(x) # поэлементный рассчет cos \n",
    "# x.cos_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5703, 0.6841],\n",
       "        [0.6216, 0.6444]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sigmoid(x) # рассчет сигмоиды\n",
    "# x.sigmoid_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Справка по математическим опреациям тут: https://pytorch.org/docs/stable/torch.html#math-operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Операции, изменяющие размер тензора: <a class=\"anchor\" id=\"размер\"></a>\n",
    "* [к оглавлению](#разделы)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7997, 0.4989, 0.1586],\n",
      "        [0.1758, 0.5943, 0.3483],\n",
      "        [0.4643, 0.4594, 0.6720],\n",
      "        [0.3840, 0.4478, 0.9048],\n",
      "        [0.2116, 0.7514, 0.1852]])\n",
      "tensor(0.5943)\n",
      "tensor([0.7997, 0.1758, 0.4643, 0.3840, 0.2116])\n",
      "tensor([0.1758, 0.5943, 0.3483])\n"
     ]
    }
   ],
   "source": [
    "# Операции среза (slicing) (работает аналогично NumPy):\n",
    "x = torch.rand(5,3)\n",
    "print(x)\n",
    "print(x[1, 1]) # элемент с индексо 1, 1 (результат: тензор размерности 0!)\n",
    "print(x[:, 0]) # все строки, столбец 0\n",
    "print(x[1, :]) # строка 1, все столбцы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5943) <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# тензор размерности 0 (скаляр), все равно остается типом 'torch.Tensor':\n",
    "print(x[1,1], type(x[1,1])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5942692160606384\n"
     ]
    }
   ],
   "source": [
    "# получение самого значения из тензора размерности 0:\n",
    "print(x[1,1].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17581236362457275\n",
      "0.5942692160606384\n",
      "0.348280131816864\n"
     ]
    }
   ],
   "source": [
    "# итерирование по тензору:\n",
    "for v in x[1, :]:\n",
    "    print(v.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.8380, -0.5930,  0.4406,  1.3580],\n",
      "        [ 1.4499,  0.3562,  0.7375,  0.7863],\n",
      "        [ 1.1890,  1.4015,  1.5559, -1.4440],\n",
      "        [-0.0319,  0.9698,  1.3826,  1.5762]]) torch.Size([4, 4]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Изменение формы тензора (reshape) с помощью torch.view():\n",
    "x = torch.randn(4, 4) # матрица 4 на 4\n",
    "print(x, x.size(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.8380, -0.5930,  0.4406,  1.3580,  1.4499,  0.3562,  0.7375,  0.7863,\n",
      "         1.1890,  1.4015,  1.5559, -1.4440, -0.0319,  0.9698,  1.3826,  1.5762]) torch.Size([16]) \n",
      "\n",
      "tensor([[[-0.8380, -0.5930,  0.4406,  1.3580],\n",
      "         [ 1.4499,  0.3562,  0.7375,  0.7863]],\n",
      "\n",
      "        [[ 1.1890,  1.4015,  1.5559, -1.4440],\n",
      "         [-0.0319,  0.9698,  1.3826,  1.5762]]]) torch.Size([2, 2, 4]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "y = x.view(16) # вектор из 16 компонент\n",
    "print(y, y.size(), '\\n')\n",
    "z = x.view(2, 2, 4) # тензор 2 на 2 на 4\n",
    "print(z, z.size(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.8380, -0.5930,  0.4406,  1.3580,  1.4499,  0.3562,  0.7375,  0.7863],\n",
      "        [ 1.1890,  1.4015,  1.5559, -1.4440, -0.0319,  0.9698,  1.3826,  1.5762]]) torch.Size([2, 8])\n"
     ]
    }
   ],
   "source": [
    "t = x.view(-1, 8)  # размер -1 означает, что размерность этой компоненты будет подобрана автоматически\n",
    "print(t, t.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> \n",
    "<img src=\"./img/lnnp2_resize1.png\" alt=\"Операции изменения размера матриц\" style=\"width: 300px;\"/><br/>\n",
    "    <b>Операции изменения размера матриц</b>    \n",
    "</center> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1830, 0.2154, 0.6007],\n",
      "        [0.4754, 0.8501, 0.3963]])\n",
      "tensor([[0.3986, 0.9731, 0.0460],\n",
      "        [0.7828, 0.7819, 0.3551]])\n"
     ]
    }
   ],
   "source": [
    "x1 = torch.rand(2,3)\n",
    "print(x1)\n",
    "y1 = torch.rand(2,3)\n",
    "print(y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1830, 0.2154, 0.6007],\n",
      "        [0.4754, 0.8501, 0.3963],\n",
      "        [0.3986, 0.9731, 0.0460],\n",
      "        [0.7828, 0.7819, 0.3551]]) torch.Size([4, 3])\n",
      "tensor([[0.1830, 0.2154, 0.6007],\n",
      "        [0.4754, 0.8501, 0.3963],\n",
      "        [0.3986, 0.9731, 0.0460],\n",
      "        [0.7828, 0.7819, 0.3551]]) torch.Size([4, 3])\n",
      "tensor([[0.1830, 0.2154, 0.6007, 0.3986, 0.9731, 0.0460],\n",
      "        [0.4754, 0.8501, 0.3963, 0.7828, 0.7819, 0.3551]]) torch.Size([2, 6])\n"
     ]
    }
   ],
   "source": [
    "# Конкатенация (concatenation):\n",
    "\n",
    "# Concatenates 2 tensors on zeroth dimension:\n",
    "concat1 = torch.cat((x1, y1))\n",
    "print(concat1, concat1.size())         \n",
    "\n",
    "# Concatenates 2 tensors on zeroth dimension\n",
    "x = torch.rand(2,3)\n",
    "concat2 = torch.cat((x1, y1), dim=0)\n",
    "print(concat2, concat2.size()) \n",
    "\n",
    "# Concatenates 2 tensors on first dimension\n",
    "x = torch.rand(2,3)\n",
    "concat3 = torch.cat((x1, y1), dim=1)\n",
    "print(concat3, concat3.size())       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1249, 0.9633, 0.0452],\n",
      "        [0.0543, 0.3090, 0.6743]])\n",
      "(tensor([[0.1249, 0.9633, 0.0452]]), tensor([[0.0543, 0.3090, 0.6743]])) torch.Size([1, 3])\n",
      "tensor([[0.1249, 0.9633],\n",
      "        [0.0543, 0.3090]]) torch.Size([2, 2]) \n",
      " tensor([[0.0452],\n",
      "        [0.6743]]) torch.Size([2, 1])\n"
     ]
    }
   ],
   "source": [
    "# Разбиение тензора (split): \n",
    "print(x1)\n",
    "\n",
    "splitted1 = x1.split(split_size=1, dim=0)\n",
    "print(splitted1, splitted1[0].size())       # 2 tensors of 2x2 and 1x2 size\n",
    "\n",
    "splitted2 = x1.split(split_size=2, dim=1)\n",
    "print(splitted2[0], splitted2[0].size(), '\\n', splitted2[1], splitted2[1].size())       # 2 tensors of 2x2 and 1x2 size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1830, 0.2154, 0.6007],\n",
      "        [0.4754, 0.8501, 0.3963]])\n",
      "tensor([[0.3986, 0.9731, 0.0460],\n",
      "        [0.7828, 0.7819, 0.3551]])\n",
      "tensor([[[0.1830, 0.2154, 0.6007],\n",
      "         [0.4754, 0.8501, 0.3963]],\n",
      "\n",
      "        [[0.3986, 0.9731, 0.0460],\n",
      "         [0.7828, 0.7819, 0.3551]]]) torch.Size([2, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "# stack:\n",
    "print(x1)\n",
    "print(y1)\n",
    "\n",
    "stacked1 = torch.stack((x1, y1), dim=0)\n",
    "print(stacked1, stacked1.size()) # возвращает тензор: 2(в результате stak!) x 2 x 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.1830, 0.2154, 0.6007],\n",
      "         [0.3986, 0.9731, 0.0460]],\n",
      "\n",
      "        [[0.4754, 0.8501, 0.3963],\n",
      "         [0.7828, 0.7819, 0.3551]]]) torch.Size([2, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "stacked2 = torch.stack((x1, y1), dim=1)\n",
    "print(stacked2, stacked2.size()) # возвращает тензор: 2 x 2(в результате stak!) x 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.7298],\n",
      "         [0.8666]],\n",
      "\n",
      "        [[0.9598],\n",
      "         [0.2414]],\n",
      "\n",
      "        [[0.4696],\n",
      "         [0.6808]]])\n",
      "tensor([[0.7298, 0.8666],\n",
      "        [0.9598, 0.2414],\n",
      "        [0.4696, 0.6808]])\n"
     ]
    }
   ],
   "source": [
    "#sqeeze and unsqueeze\n",
    "x2 = torch.rand(3, 2, 1) # a tensor of size 3x2x1\n",
    "print(x2)\n",
    "squeezed1 = x2.squeeze()\n",
    "print(squeezed1)  # remove the 1 sized dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3965, 0.5168, 0.6922])\n",
      "tensor([[0.3965, 0.5168, 0.6922]]) torch.Size([1, 3])\n",
      "tensor([[0.3965],\n",
      "        [0.5168],\n",
      "        [0.6922]]) torch.Size([3, 1])\n"
     ]
    }
   ],
   "source": [
    "x3 = torch.rand(3)\n",
    "print(x3)\n",
    "\n",
    "with_fake_dimension1 = x3.unsqueeze(0)\n",
    "print(with_fake_dimension1, with_fake_dimension1.size()) # added a fake zeroth dimensionz \n",
    "\n",
    "with_fake_dimension2 = x3.unsqueeze(1)\n",
    "print(with_fake_dimension2, with_fake_dimension2.size()) # added a fake zeroth dimensionz "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3., 4.]) tensor([0., 1., 2.])\n",
      "tensor([[0., 1., 2.],\n",
      "        [0., 2., 4.],\n",
      "        [0., 3., 6.],\n",
      "        [0., 4., 8.]]) torch.Size([4, 3])\n"
     ]
    }
   ],
   "source": [
    "# Распространение (broadcasting) - так же как в NumPy:\n",
    "\n",
    "t1 = torch.arange(1.0, 5.0)\n",
    "t3 = torch.arange(0.0, 3.0)\n",
    "print(t1, t3)\n",
    "tm = t1.ger(t3)\n",
    "print(tm, tm.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (4) must match the size of tensor b (3) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-6ea1dd71dd31>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mt1\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (4) must match the size of tensor b (3) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "t1 * tm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4]), torch.Size([4, 3]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1.size(), tm.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.],\n",
      "        [2.],\n",
      "        [3.],\n",
      "        [4.]])\n",
      "tensor([[0., 1., 2.],\n",
      "        [0., 2., 4.],\n",
      "        [0., 3., 6.],\n",
      "        [0., 4., 8.]])\n"
     ]
    }
   ],
   "source": [
    "print(t1.unsqueeze(1))\n",
    "print(tm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  2.],\n",
       "        [ 0.,  4.,  8.],\n",
       "        [ 0.,  9., 18.],\n",
       "        [ 0., 16., 32.]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1.unsqueeze(1) * tm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 1]), torch.Size([4, 3]))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1.unsqueeze(1).size(), tm.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Операции агрегации: <a class=\"anchor\" id=\"агрегации\"></a>\n",
    "* [к оглавлению](#разделы)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(30.)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat = torch.tensor(\n",
    "        [[0., 1., 2.],\n",
    "        [0., 2., 4.],\n",
    "        [0., 3., 6.],\n",
    "        [0., 4., 8.]])\n",
    "\n",
    "# суммирование по всем элементам:\n",
    "mat.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0., 10., 20.])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# суммирование по оси 0:\n",
    "mat.sum(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3.,  6.,  9., 12.])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# суммирование по оси 1:\n",
    "mat.sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.5000)\n",
      "tensor([0.0000, 2.5000, 5.0000])\n",
      "tensor([1., 2., 3., 4.])\n"
     ]
    }
   ],
   "source": [
    "# получение среднего значения:\n",
    "\n",
    "print(mat.mean())\n",
    "print(mat.mean(dim=0))\n",
    "print(mat.mean(dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Матричные операции: <a class=\"anchor\" id=\"матричные\"></a>\n",
    "* [к оглавлению](#разделы)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:\n",
      " tensor([[0.7255, 0.9459],\n",
      "        [0.0180, 0.9965]])\n",
      "\n",
      "y:\n",
      " tensor([[0.5618, 0.6862],\n",
      "        [0.2016, 0.1258]])\n",
      "\n",
      "z = torch.mul(x,y):\n",
      " tensor([[0.4076, 0.6491],\n",
      "        [0.0036, 0.1253]])\n",
      "\n",
      "z = torch.mul(x,y):\n",
      " tensor([[0.4076, 0.6491],\n",
      "        [0.0036, 0.1253]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Умножение (поэлементное!):\n",
    "\n",
    "x = torch.rand(2, 2)\n",
    "print(f'x:\\n {x}\\n')\n",
    "y = torch.rand(2, 2)\n",
    "print(f'y:\\n {y}\\n')\n",
    "\n",
    "z = x * y\n",
    "print(f'z = torch.mul(x,y):\\n {z}\\n')\n",
    "z = torch.mul(x,y)\n",
    "print(f'z = torch.mul(x,y):\\n {z}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2450, -0.9958,  0.3320],\n",
      "        [-1.1015,  1.3226,  3.2153]]) torch.Size([2, 3])\n",
      "tensor([-0.0979,  2.0161, -0.1482]) torch.Size([3])\n",
      "tensor([-2.0808,  2.2977]) torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "# Умножение матрицы на вектор:\n",
    "\n",
    "# torch.mv(input, vec, out=None) → Tensor\n",
    "# Performs a matrix-vector product of the matrix input and the vector vec.\n",
    "# If input is a (n \\times m)(n×m) tensor, vec is a 1-D tensor of size mm , out will be 1-D of size nn .\n",
    "\n",
    "mat = torch.randn(2, 3)\n",
    "print(mat, mat.size())\n",
    "vec = torch.randn(3)\n",
    "print(vec, vec.size())\n",
    "res = torch.mv(mat, vec)\n",
    "print(res, res.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.6114,  0.1754, -0.1479],\n",
      "        [-0.8400, -1.4489, -0.1735]]) torch.Size([2, 3])\n",
      "tensor([[-0.2815,  0.7116, -1.1436],\n",
      "        [ 0.1062,  0.8233,  1.0840],\n",
      "        [ 0.4111,  1.1746, -0.1564]]) torch.Size([3, 3])\n",
      "tensor([[ 0.4115, -1.1759,  2.0561],\n",
      "        [ 0.0113, -1.9944, -0.5829]]) torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "# Умножение матрицы на матрицу:\n",
    "\n",
    "# torch.mm(input, mat2, out=None) → Tensor\n",
    "# Performs a matrix multiplication of the matrices input and mat2.\n",
    "# If input is a (n×m) tensor, mat2 is a (m×p) tensor, out will be a (n×p) tensor.\n",
    "\n",
    "mat1 = torch.randn(2, 3)\n",
    "print(mat1, mat1.size())\n",
    "mat2 = torch.randn(3, 3)\n",
    "print(mat2, mat2.size())\n",
    "res = torch.mm(mat1, mat2)\n",
    "print(res, res.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4115, -1.1759,  2.0561],\n",
       "        [ 0.0113, -1.9944, -0.5829]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat1.mm(mat2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) torch.Size([3])\n",
      "tensor([1, 2]) torch.Size([2])\n",
      "tensor([[1, 2],\n",
      "        [2, 4],\n",
      "        [3, 6]]) torch.Size([3, 2])\n"
     ]
    }
   ],
   "source": [
    "# Outer product of 2 vectors\n",
    "vec1 = torch.arange(1, 4)    # Size 3\n",
    "print(vec1, vec1.size())\n",
    "vec2 = torch.arange(1, 3)    # Size 2\n",
    "print(vec2, vec2.size())\n",
    "res = torch.ger(vec1, vec2) # vec1 - рассматривается как вектор-столбец; vec2 - рассматривается как вектор-строка\n",
    "print(res, res.size()) # Size 3x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [2, 4],\n",
       "        [3, 6]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec1.ger(vec2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Функция matmul__\n",
    "\n",
    "* Matrix product of two tensors: `torch.matmul(input, other, out=None)` → Tensor\n",
    "* The behavior depends on the dimensionality of the tensors as follows:\n",
    "    * If __both tensors are 1-dimensional__, the __dot product (scalar) is returned__.\n",
    "    * If __both arguments are 2-dimensional__, the __matrix-matrix product is returned__.\n",
    "    * If the __first argument is 1-dimensional and the second argument is 2-dimensional__, a 1 is prepended to its dimension for the purpose of the matrix multiply. After the matrix multiply, the prepended dimension is removed.\n",
    "    * If the __first argument is 2-dimensional and the second argument is 1-dimensional__, the matrix-vector product is returned.\n",
    "    * If __both arguments are at least 1-dimensional and at least one argument is N-dimensional (where N > 2)__, then a batched matrix multiply is returned. If the first argument is 1-dimensional, a 1 is prepended to its dimension for the purpose of the batched matrix multiply and removed after. If the second argument is 1-dimensional, a 1 is appended to its dimension for the purpose of the batched matrix multiple and removed after. The non-matrix (i.e. batch) dimensions are broadcasted (and thus must be broadcastable). For example, if input is a $j \\times 1 \\times n \\times m$ tensor and other is a $k \\times m \\times p$ tensor, out will be an $j \\times k \\times n \\times p$ tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(3*4).view(3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-2.5219, -1.2146,  1.3170]) torch.Size([3])\n",
      "tensor([ 0.2303,  0.9512, -0.0546]) torch.Size([3])\n",
      "tensor(-1.8081) torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "# vector x vector\n",
    "tensor1 = torch.randn(3)\n",
    "print(tensor1, tensor1.size())\n",
    "tensor2 = torch.randn(3)\n",
    "print(tensor2, tensor2.size())\n",
    "res = torch.matmul(tensor1, tensor2)\n",
    "print(res, res.size()) # результат: скаляр"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-1.8081)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Вызов функции matmul можно выполнять с помощью оператора @:\n",
    "tensor1 @ tensor2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11]]) torch.Size([3, 4])\n",
      "tensor([0, 1, 2]) torch.Size([3])\n",
      "tensor([20, 23, 26, 29]) torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "# vector x matrix \n",
    "tensor1 = torch.arange(3*4).view(3, 4)\n",
    "print(tensor1, tensor1.size())\n",
    "tensor2 = torch.arange(3)\n",
    "print(tensor2, tensor2.size())\n",
    "\n",
    "res = torch.matmul(tensor2, tensor1)\n",
    "print(res, res.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([20, 23, 26, 29])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# или:\n",
    "tensor2 @ tensor1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11]]) torch.Size([3, 4])\n",
      "tensor([0, 1, 2, 3]) torch.Size([4])\n",
      "tensor([14, 38, 62]) torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "# matrix x vector\n",
    "tensor1 = torch.arange(3*4).view(3, 4)\n",
    "print(tensor1, tensor1.size())\n",
    "tensor2 = torch.arange(4)\n",
    "print(tensor2, tensor2.size())\n",
    "\n",
    "res = torch.matmul(tensor1, tensor2)\n",
    "print(res, res.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([14, 38, 62])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor1 @ tensor2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.0254,  0.7122, -2.5060,  0.5180],\n",
      "         [ 0.1458, -0.8855, -0.8308,  1.5698],\n",
      "         [-0.7911,  0.8250, -0.9246, -0.1922]],\n",
      "\n",
      "        [[-0.3259, -0.8213,  1.5900, -0.1392],\n",
      "         [-0.5806, -0.1336, -2.4994, -0.2150],\n",
      "         [-0.1507, -1.1597,  0.4157,  0.5377]],\n",
      "\n",
      "        [[ 0.1935, -0.6100, -0.0840, -0.2509],\n",
      "         [ 0.2435,  0.0852, -0.7656, -0.5838],\n",
      "         [-1.1525,  1.2272, -0.6801,  1.1422]],\n",
      "\n",
      "        [[ 1.5298,  0.4393,  1.0724, -1.3998],\n",
      "         [ 0.5910,  1.0698,  0.0492, -0.4684],\n",
      "         [-0.5860,  0.3775, -0.4975,  0.1747]],\n",
      "\n",
      "        [[ 0.6234, -1.6125,  0.0581, -0.9023],\n",
      "         [ 0.8492,  0.4678,  2.2095, -0.4018],\n",
      "         [-0.4183,  1.1057,  0.4946,  0.2117]],\n",
      "\n",
      "        [[-0.4135, -1.1620, -0.4104,  0.7465],\n",
      "         [-1.5399,  0.3171,  0.6196, -1.0964],\n",
      "         [-1.4138, -0.7486, -0.2011, -0.4922]],\n",
      "\n",
      "        [[-0.1190,  0.5037,  1.6496,  0.6041],\n",
      "         [ 0.0585,  1.0287, -0.0672,  0.6690],\n",
      "         [-0.2793, -0.8093, -1.3930, -0.2564]],\n",
      "\n",
      "        [[-0.2652,  0.3194,  0.1951,  0.4310],\n",
      "         [-0.9333, -2.0235, -0.0407,  1.4903],\n",
      "         [-0.2456, -0.3495,  0.5053,  0.7812]],\n",
      "\n",
      "        [[ 0.5721, -0.2114, -2.9636,  0.6201],\n",
      "         [-1.0270,  0.1474,  0.7315, -0.6116],\n",
      "         [ 1.0629,  0.8071,  0.5145,  0.4959]],\n",
      "\n",
      "        [[ 0.0760, -0.5637, -0.7976,  0.0616],\n",
      "         [-1.1659, -1.4374, -0.7419,  0.4414],\n",
      "         [-0.4875, -0.7246,  0.1285, -0.3838]]]) torch.Size([10, 3, 4]) \n",
      "------------\n",
      "tensor([ 0.1706, -0.5846,  0.1843, -1.3673]) torch.Size([4]) \n",
      "------------\n",
      "tensor([[-1.5908, -1.7570, -0.5249],\n",
      "        [ 0.9079, -0.1876, -0.0064],\n",
      "        [ 0.7172,  0.6489, -2.6011],\n",
      "        [ 2.1158,  0.1250, -0.6511],\n",
      "        [ 2.2935,  0.8279, -0.9160],\n",
      "        [-0.4876,  1.1653,  0.8324],\n",
      "        [-0.8368, -1.5186,  0.5194],\n",
      "        [-0.7854, -1.0215, -0.8126],\n",
      "        [-1.1729,  0.7098, -0.8738],\n",
      "        [ 0.1113, -0.0989,  0.8890]]) torch.Size([10, 3])\n"
     ]
    }
   ],
   "source": [
    "# batched matrix x broadcasted vector\n",
    "tensor1 = torch.randn(10, 3, 4)\n",
    "print(tensor1, tensor1.size(), '\\n------------')\n",
    "tensor2 = torch.randn(4)\n",
    "print(tensor2, tensor2.size(), '\\n------------')\n",
    "res = torch.matmul(tensor1, tensor2)\n",
    "print(res, res.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3, 4]) \n",
      "------------\n",
      "torch.Size([10, 4, 5]) \n",
      "------------\n",
      "torch.Size([10, 3, 5])\n"
     ]
    }
   ],
   "source": [
    "# batched matrix x batched matrix\n",
    "tensor1 = torch.randn(10, 3, 4)\n",
    "print(tensor1.size(), '\\n------------')\n",
    "tensor2 = torch.randn(10, 4, 5)\n",
    "print(tensor2.size(), '\\n------------')\n",
    "res = torch.matmul(tensor1, tensor2)\n",
    "print(res.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3, 4]) \n",
      "------------\n",
      "tensor([[ 2.3362,  0.1706,  0.4528,  0.8596,  1.0453],\n",
      "        [-0.0351,  0.2272, -0.4056, -0.2502,  0.9134],\n",
      "        [-1.5136,  0.4217,  1.3492,  0.6766,  0.9003],\n",
      "        [-1.6946, -1.3057,  1.5708,  0.5506, -2.0987]]) torch.Size([4, 5]) \n",
      "------------\n",
      "torch.Size([10, 3, 5])\n"
     ]
    }
   ],
   "source": [
    "# batched matrix x broadcasted matrix\n",
    "tensor1 = torch.randn(10, 3, 4)\n",
    "print(tensor1.size(), '\\n------------')\n",
    "tensor2 = torch.randn(4, 5)\n",
    "print(tensor2, tensor2.size(), '\\n------------')\n",
    "res = torch.matmul(tensor1, tensor2)\n",
    "print(res.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Спасибо за внимание!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Технический раздел:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * И Введение в искусственные нейронные сети\n",
    "     * Базовые понятия и история\n",
    " * И Машинное обучение и концепция глубокого обучения\n",
    " * И Почему глубокое обучение начало приносить плоды и активно использоваться только после 2010 г?\n",
    "     * Производительность оборудования\n",
    "     * Доступность наборов данных и тестов\n",
    "     * Алгоритмические достижения в области глубокого обучения\n",
    "         * Улчшенные подходы к регуляризации\n",
    "         * Улучшенные схемы инициализации весов\n",
    "         * (повтор) Усовершенствованные методы градиентного супска\n",
    "         \n",
    "\n",
    "* Обратное распространение ошибки\n",
    " * Оптимизация\n",
    "     * Стохастический градиентный спуск\n",
    "     * Усовершенствованные методы градиентного супска\n",
    "* Введение в PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/> next <em class=\"qs\"></em> qs line \n",
    "<br/> next <em class=\"an\"></em> an line \n",
    "<br/> next <em class=\"nt\"></em> an line \n",
    "<br/> next <em class=\"df\"></em> df line \n",
    "<br/> next <em class=\"ex\"></em> ex line \n",
    "<br/> next <em class=\"pl\"></em> pl line \n",
    "<br/> next <em class=\"mn\"></em> mn line \n",
    "<br/> next <em class=\"plmn\"></em> plmn line \n",
    "<br/> next <em class=\"hn\"></em> hn line "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Работа с графом потока вычислений нужна  для того, чтобы решить __задачу обучения многослойной ИНС__. А эта задача требует после получения резуьтатов и оценки ошибки __выполнения обратного прохода__ дающего градиент ошибки для весов (параметров) модели и последующей процедуры оптимизации весов. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> \n",
    "<img src=\"./img/ker_7.png\" alt=\"\" style=\"width: 500px;\"/>\n",
    "<img src=\"./img/ker_8.png\" alt=\"\" style=\"width: 500px;\"/>    \n",
    "<img src=\"./img/ker_9.png\" alt=\"\" style=\"width: 500px;\"/>        \n",
    "<img src=\"./img/ker_10.png\" alt=\"\" style=\"width: 500px;\"/>        \n",
    "<img src=\"./img/ker_11.png\" alt=\"\" style=\"width: 500px;\"/>            \n",
    "<img src=\"./img/ker_12.png\" alt=\"\" style=\"width: 500px;\"/>                \n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
