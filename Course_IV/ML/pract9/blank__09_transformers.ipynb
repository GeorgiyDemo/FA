{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kc07UhvrY8E7"
      },
      "source": [
        "pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuAsljnJ5vNP"
      },
      "source": [
        "pip install sentencepiece"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6VMYUruTL-y"
      },
      "source": [
        "## 1. Pipelines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgcKfcWPUiaS"
      },
      "source": [
        "from transformers import pipeline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-QJBazMZRe9"
      },
      "source": [
        "[Документация по transformers.pipeline](https://huggingface.co/transformers/main_classes/pipelines.html)\n",
        "\n",
        "[Model hub](https://huggingface.co/models)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-INRBbdhkQn0"
      },
      "source": [
        "1.1 Среди предобученных моделей найдите модель для перевода текста с русского языка на английский. Протестируйте данную модель на нескольких предложениях, используя `transformers.pipeline`. Выведите результаты работы в следующем виде:\n",
        "\n",
        "```\n",
        "sentence1_ru -> sentence1_en\n",
        "sentence2_ru -> sentence2_en\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vuKwZ_GNkcAX"
      },
      "source": [
        "1.2 Среди предобученных моделей найдите модель для поиска ответа в тексте. Протестируйте данную модель на нескольких предложениях, используя `transformers.pipeline`. Выведите на экран результаты в следующем виде:\n",
        "\n",
        "```\n",
        "Q: ...\n",
        "A: ...\n",
        "Q: ...\n",
        "A: ...\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "faCSDP3FW6xo"
      },
      "source": [
        "1.3 Среди предобученных моделей найдите модель для классификации тональности русскоязычного текста (позитивный/негативный или позитивный/негативный/нейтральный). Протестируйте данную модель на нескольких предложениях, используя `transformers.pipeline`. Выведите результаты работы в следующем виде:\n",
        "\n",
        "```\n",
        "sentence1 -> class1\n",
        "sentence2 -> class2\n",
        "...\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRxaPqDAaVFn"
      },
      "source": [
        "## 2. Токенизаторы и модели"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mkTDgG7b8u1"
      },
      "source": [
        "[Auto Classes](https://huggingface.co/transformers/model_doc/auto.html)\n",
        "\n",
        "[Tokenizer](https://huggingface.co/transformers/main_classes/tokenizer.html?highlight=tokenizer#transformers.PreTrainedTokenizer.__call__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFo9Bdaxkv85"
      },
      "source": [
        "2.1 Решите задачу 1.2, создав объект токенизатора (`transformers.AutoTokenizer`) и модель (`transformers.AutoModelForQuestionAnswering`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xdd92sDWZvHV"
      },
      "source": [
        "from transformers import AutoTokenizer\n",
        "from transformers import AutoModelForQuestionAnswering"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrqsKWyGllkc"
      },
      "source": [
        "2.2 Решите задачу 1.3, создав объект токенизатора (`transformers.AutoTokenizer`) и модель (`transformers.AutoModelForSequenceClassification`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIEcXyiugIT3"
      },
      "source": [
        "from transformers import AutoModelForSequenceClassification"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbrNEZ2in3zm"
      },
      "source": [
        "# 3. Fine tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhAOrQS0SX_o"
      },
      "source": [
        "3.1 Дообучите классификатор отзывов на основе модели `distilbert-base-uncased`.\n",
        "\n",
        "Датасет: https://yadi.sk/d/mRXgc2aJSCncdw\n",
        "\n",
        "* считайте данные, разбейте на обучающее и тестовое множество;\n",
        "* создайте токенизатор `AutoTokenizer` для модели `distilbert-base-uncased` и преобразуйте с его помощью текстовые данные. Не забудьте выровнять длину всех последовательностей при помощи параметра `padding`;\n",
        "* опишите класс `ReviewDataset`:\n",
        "  * в данном случае удобнее, чтобы метод `__getitem__` возвращал словарь, а не кортеж (см. класс `MyDataset` ниже). Этот словарь должен содержать все данные, полученные после работы токенизатора плюс по ключу `label` должен находиться правильный ответ;\n",
        "* создайте модель `AutoModelForSequenceClassification` с предобученными весами на основе `distilbert-base-uncased`;\n",
        "  * при создании модели укажите параметр `num_labels=2`\n",
        "* дообучите модель:\n",
        "  * удобная особенность моделей из `transformers`: в метод `__call__` модели можно передать параметр `labels`, содержащий правильные ответы для обучения; тогда в словаре, который вернет метод `__call__` будет ключ `loss`, содержащий тензор со значением функции потерь, у которого можно вызвать метод `backward` и т.д. Таким образом, в данном случае функцию потерь объявлять не нужно;\n",
        "  * для обучения используйте оптимизатор `transformers.AdamW` вместо `torch.optim.Adam`;\n",
        "* измерьте значение accuracy на тестовом множестве."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Zn1p_jwTDgp"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import AutoModelForSequenceClassification, AdamW, AutoTokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0VJTA8lMVOX",
        "outputId": "30409b2b-1ba7-4240-f028-abd6f26899ea"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amYi14CgMdoF",
        "outputId": "1554e44c-ce12-416d-adb6-6b3462d3d4d3"
      },
      "source": [
        "cd drive/MyDrive/datasets"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'drive/MyDrive/datasets'\n",
            "/content/drive/MyDrive/datasets\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}